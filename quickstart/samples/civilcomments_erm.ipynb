{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/hyang/SpuCo\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25h\u001b[31mERROR: Package 'spuco' requires a different Python: 3.8.5 not in '>=3.10.0'\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "device = torch.device(\"cuda:7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spuco'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1863268/1595488782.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mspuco\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spuco'"
     ]
    }
   ],
   "source": [
    "from spuco.utils import set_seed\n",
    "\n",
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wilds import get_dataset\n",
    "from spuco.utils import initialize_bert_transform\n",
    "\n",
    "# Load the full dataset, and download it if necessary\n",
    "dataset = get_dataset(dataset=\"civilcomments\", download=True, root_dir=\"/data\")\n",
    "transform = initialize_bert_transform(model=\"distilbert-base-uncased\", max_token_length=300)\n",
    "\n",
    "# Get the training set\n",
    "train_data = dataset.get_subset(\n",
    "    \"train\",\n",
    "    transform=transform,\n",
    ")\n",
    "\n",
    "# Get the training set\n",
    "test_data = dataset.get_subset(\n",
    "    \"test\",\n",
    "    transform=transform,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Partitioning data indices into groups: 100%|██████████| 269038/269038 [00:00<00:00, 3196360.59it/s]\n",
      "Partitioning data indices into groups: 100%|██████████| 133782/133782 [00:00<00:00, 3278503.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from spuco.utils import WILDSDatasetWrapper\n",
    "\n",
    "trainset = WILDSDatasetWrapper(dataset=train_data, metadata_spurious_label=\"identity_any\", verbose=True)\n",
    "testset = WILDSDatasetWrapper(dataset=test_data, metadata_spurious_label=\"identity_any\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(1, 1): 0.06904229142351638,\n",
       " (1, 0): 0.044380347757565844,\n",
       " (0, 0): 0.5338576706636238,\n",
       " (0, 1): 0.35271969015529403}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.group_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBert: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBert from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBert from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from spuco.models import model_factory \n",
    "\n",
    "model = model_factory(\"distilbert\", (0,0,0), trainset.num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from spuco.invariant_train import ERM \n",
    "\n",
    "lr = 1e-5\n",
    "weight_decay = 0.01\n",
    "num_epochs = 1\n",
    "batch_size = 16\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "params = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': weight_decay},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "optimizer = AdamW(\n",
    "    params,\n",
    "    lr=lr, \n",
    "    weight_decay=weight_decay)\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "n_train_steps = len(trainset) // batch_size * num_epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_training_steps=n_train_steps,\n",
    "    num_warmup_steps=0)\n",
    "\n",
    "erm = ERM(\n",
    "    model=model,\n",
    "    num_epochs=num_epochs,\n",
    "    trainset=trainset,\n",
    "    batch_size=batch_size,\n",
    "    optimizer=optimizer,\n",
    "    lr_scheduler=scheduler,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    device=device,\n",
    "    verbose=True,\n",
    ")\n",
    "erm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spuco.evaluate import Evaluator\n",
    "\n",
    "evaluator = Evaluator(\n",
    "    testset=testset,\n",
    "    group_partition=testset.group_partition,\n",
    "    group_weights=trainset.group_weights,\n",
    "    batch_size=64,\n",
    "    model=model,\n",
    "    device=device,\n",
    "    verbose=True\n",
    ")\n",
    "evaluator.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
